{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BatchNorm(nn.Module):\n",
    "\n",
    "    \"\"\"Batch normalization layer for convolutional neural network\"\"\"\n",
    "\n",
    "    def __init__(self, num_channels: int = 3, eps: float = 1e-5, momentum:float = 0.1,\n",
    "    is_affine: bool = True, track_running_stats: bool = True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.is_affine = is_affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "\n",
    "        if is_affine: # Create parameters for γ and β for scale and shift\n",
    "            self.scale = nn.Parameter(torch.ones(num_channels))\n",
    "            self.shift = nn.Parameter(torch.zeros(num_channels))\n",
    "\n",
    "        if track_running_stats: # Create buffers to store exponential moving averages of mean E[x(k)] and variance Var[x(k)]\n",
    "            # Initialize as N(0, 1)\n",
    "            self.register_buffer('exp_mean', nn.Parameter(torch.zeros(num_channels)))\n",
    "            self.register_buffer('exp_var', nn.Parameter(torch.ones(num_channels)))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        \"\"\"\n",
    "        x: (B, C, D)\n",
    "        D = l if 1D, h x w if 2D, h x w x t if 3D\n",
    "        \"\"\"\n",
    "        \n",
    "        x_shape_old = x.shape\n",
    "\n",
    "        assert self.num_channels == x_shape_old[1]\n",
    "\n",
    "        x = x.flatten(start_dim=2) # (B, C, n)\n",
    "                                   # n is overall number of object's features\n",
    "        #print(f'new_shape = {x.shape}')\n",
    "        if self.training or not self.track_running_stats: # We will calculate the mini-batch mean and variance \n",
    "                                                          # if we are in training mode or \n",
    "                                                          # if we have not tracked exponential moving averages\n",
    "\n",
    "            # calculate mean and variance along batch and feature dimensions (for each channel)\n",
    "            batch_mean = x.mean(dim = [0, -1])\n",
    "            batch_var = x.var(dim = [0, -1])\n",
    "\n",
    "            if self.training and self.track_running_stats:\n",
    "                # update exponential moving averages\n",
    "                self.exp_mean = (1 - self.momentum) * self.exp_mean + self.momentum * batch_mean\n",
    "                self.exp_var = (1 - self.momentum) * self.exp_var + self.momentum * batch_var\n",
    "        else: # if not training and tracking stats\n",
    "            batch_mean = self.exp_mean\n",
    "            batch_var = self.exp_var\n",
    "        \n",
    "        # normalize x to N(0, 1)\n",
    "        x_hat = (x - batch_mean.reshape(1, -1, 1)) / torch.sqrt(batch_var + self.eps).reshape(1, -1, 1)\n",
    "        #x_hat = x_hat.reshape(1, -1 , 1)\n",
    "\n",
    "        if self.is_affine:\n",
    "            x_hat = self.scale.reshape(1, -1, 1) * x_hat #+ self.shift.reshape(1, -1, 1)\n",
    "        \n",
    "        return x_hat.reshape(x_shape_old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    shape: torch.Size([2, 3, 2, 4])\n",
      "    mean: tensor([0.5102, 0.5535, 0.3655])\n",
      "    var: tensor([0.0559, 0.0838, 0.0954])\n",
      "    \n",
      "\n",
      "    shape: torch.Size([2, 3, 2, 4])\n",
      "    mean: tensor([ 2.5705e-07, -5.9605e-08,  2.9802e-08], grad_fn=<MeanBackward1>)\n",
      "    var: tensor([0.9998, 0.9999, 0.9999], grad_fn=<VarBackward0>)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def print_info(x):\n",
    "    print(f\"\"\"\n",
    "    shape: {x.shape}\n",
    "    mean: {x.mean(dim = [0, 2, 3])}\n",
    "    var: {x.var(dim=[0, 2, 3])}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "x = torch.rand([2, 3, 2, 4])\n",
    "print_info(x)\n",
    "\n",
    "bn = BatchNorm(3)\n",
    "x = bn(x)\n",
    "print_info(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d75bf56f6470173b1ac7bd9da905d241387559ca422a37986719b723ab6f9d4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
