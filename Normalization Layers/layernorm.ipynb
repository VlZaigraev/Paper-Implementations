{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a PyTorch implementation of Layer Normalization.\n",
    "\n",
    "    Layer normalization LN normalizes the input X as follows:\n",
    "\n",
    "When input X∈RB×C is a batch of embeddings, where B is the batch size and C is the number of features. γ∈RC and β∈RC. LN(X)=γCVar​[X]+ϵ\n",
    "\n",
    "​X−CE​[X]​+β\n",
    "\n",
    "When input X∈RL×B×C is a batch of a sequence of embeddings, where B is the batch size, C is the number of channels, L is the length of the sequence. γ∈RC and β∈RC. LN(X)=γCVar​[X]+ϵ\n",
    "\n",
    "​X−CE​[X]​+β\n",
    "\n",
    "When input X∈RB×C×H×W is a batch of image representations, where B is the batch size, C is the number of channels, H is the height and W is the width. This is not a widely used scenario. γ∈RC×H×W and β∈RC×H×W. LN(X)=γC,H,WVar​[X]+ϵ\n",
    "​X−C,H,WE​[X]​+β\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 normalized_shape = Union[int, List[int], torch.Size],\n",
    "                 eps: float = 1e-5,\n",
    "                 apply_affine: bool = True, ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        normalized_shape S is the shape of the elements (except the batch). The input should then be X∈R∗×S[0]×S[1]×...×S[n]\n",
    "        eps is ϵ, used in Var[X]+ϵ for numerical stability\n",
    "        apply_affine is whether to scale and shift the normalized value\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.apply_affine = apply_affine\n",
    "\n",
    "        if apply_affine:\n",
    "            self.scale = nn.Parameter(torch.ones(normalized_shape))\n",
    "            self.shift = nn.Parameter(torch.zeros(normalized_shape))\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x is a tensor of shape [*, S[0], S[1], ..., S[n]].\n",
    "        * could be any number of dimensions.\n",
    "        For example, in an NLP task this will be [seq_len, batch_size, features]\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.normalized_shape == x.shape[-len(self.normalized_shape):]\n",
    "\n",
    "        var, mean = torch.var_mean(x,\n",
    "                                   dim = [-(i+1) for i in range(len(self.normalized_shape))],\n",
    "                                   keepdim=True)\n",
    "\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        return self.scale*x_hat if self.apply_affine else x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d75bf56f6470173b1ac7bd9da905d241387559ca422a37986719b723ab6f9d4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
